{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OFawcWGbxJ5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "lr = 0.0002\n",
        "epochs = 50\n",
        "latent_dim = 100\n",
        "img_size = 28\n",
        "img_shape = (1, img_size, img_size)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cH28BfhZNEBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
        "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "9yV1KVWHNJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *img_shape)\n",
        "        return img\n",
        "\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "QU3vrMC3NdUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "6Qv9wqFeNoJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "eEgFwyP0Nmj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        valid = torch.ones(imgs.size(0), 1, device=device, requires_grad=False)\n",
        "        fake = torch.zeros(imgs.size(0), 1, device=device, requires_grad=False)\n",
        "\n",
        "\n",
        "        real_imgs = imgs.to(device)\n",
        "\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
        "        generated_imgs = generator(z)\n",
        "        g_loss = adversarial_loss(discriminator(generated_imgs), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        if i % 400 == 0:\n",
        "            print(f\"Epoch {epoch}/{epochs} Batch {i}/{len(dataloader)} \\\n",
        "                  Loss D: {d_loss.item():.6f}, Loss G: {g_loss.item():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2_JIaBqNyhg",
        "outputId": "ce4758c4-28bb-4600-c3c8-a8ca70bb2239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50 Batch 0/600                   Loss D: 0.682669, Loss G: 0.724249\n",
            "Epoch 0/50 Batch 400/600                   Loss D: 0.340233, Loss G: 1.346480\n",
            "Epoch 1/50 Batch 0/600                   Loss D: 0.351534, Loss G: 1.308863\n",
            "Epoch 1/50 Batch 400/600                   Loss D: 0.496394, Loss G: 3.027916\n",
            "Epoch 2/50 Batch 0/600                   Loss D: 0.437646, Loss G: 0.679266\n",
            "Epoch 2/50 Batch 400/600                   Loss D: 0.296584, Loss G: 2.031601\n",
            "Epoch 3/50 Batch 0/600                   Loss D: 0.467400, Loss G: 0.629870\n",
            "Epoch 3/50 Batch 400/600                   Loss D: 0.259872, Loss G: 1.536625\n",
            "Epoch 4/50 Batch 0/600                   Loss D: 0.248083, Loss G: 3.128299\n",
            "Epoch 4/50 Batch 400/600                   Loss D: 0.477719, Loss G: 3.817528\n",
            "Epoch 5/50 Batch 0/600                   Loss D: 0.312823, Loss G: 1.067905\n",
            "Epoch 5/50 Batch 400/600                   Loss D: 0.380523, Loss G: 2.907200\n",
            "Epoch 6/50 Batch 0/600                   Loss D: 0.203087, Loss G: 1.694281\n",
            "Epoch 6/50 Batch 400/600                   Loss D: 0.279373, Loss G: 1.337377\n",
            "Epoch 7/50 Batch 0/600                   Loss D: 0.281417, Loss G: 1.599325\n",
            "Epoch 7/50 Batch 400/600                   Loss D: 0.351702, Loss G: 0.932524\n",
            "Epoch 8/50 Batch 0/600                   Loss D: 0.361176, Loss G: 0.903066\n",
            "Epoch 8/50 Batch 400/600                   Loss D: 0.427474, Loss G: 4.542870\n",
            "Epoch 9/50 Batch 0/600                   Loss D: 0.300898, Loss G: 2.409749\n",
            "Epoch 9/50 Batch 400/600                   Loss D: 0.307098, Loss G: 3.216710\n",
            "Epoch 10/50 Batch 0/600                   Loss D: 0.223630, Loss G: 2.488396\n",
            "Epoch 10/50 Batch 400/600                   Loss D: 0.263307, Loss G: 1.863790\n",
            "Epoch 11/50 Batch 0/600                   Loss D: 0.414497, Loss G: 0.969232\n",
            "Epoch 11/50 Batch 400/600                   Loss D: 0.196409, Loss G: 1.754251\n",
            "Epoch 12/50 Batch 0/600                   Loss D: 0.297746, Loss G: 1.442467\n",
            "Epoch 12/50 Batch 400/600                   Loss D: 0.253699, Loss G: 1.423137\n",
            "Epoch 13/50 Batch 0/600                   Loss D: 0.192427, Loss G: 2.315871\n",
            "Epoch 13/50 Batch 400/600                   Loss D: 0.258407, Loss G: 2.990203\n",
            "Epoch 14/50 Batch 0/600                   Loss D: 0.361318, Loss G: 1.065701\n",
            "Epoch 14/50 Batch 400/600                   Loss D: 0.272898, Loss G: 1.570280\n",
            "Epoch 15/50 Batch 0/600                   Loss D: 0.225026, Loss G: 2.091440\n",
            "Epoch 15/50 Batch 400/600                   Loss D: 0.244539, Loss G: 1.975760\n",
            "Epoch 16/50 Batch 0/600                   Loss D: 0.453109, Loss G: 0.882327\n",
            "Epoch 16/50 Batch 400/600                   Loss D: 0.291175, Loss G: 1.480714\n",
            "Epoch 17/50 Batch 0/600                   Loss D: 0.422051, Loss G: 3.641912\n",
            "Epoch 17/50 Batch 400/600                   Loss D: 0.307291, Loss G: 2.169709\n",
            "Epoch 18/50 Batch 0/600                   Loss D: 0.468808, Loss G: 3.231437\n",
            "Epoch 18/50 Batch 400/600                   Loss D: 0.313922, Loss G: 1.494358\n",
            "Epoch 19/50 Batch 0/600                   Loss D: 0.279046, Loss G: 1.411792\n",
            "Epoch 19/50 Batch 400/600                   Loss D: 0.389058, Loss G: 1.150339\n",
            "Epoch 20/50 Batch 0/600                   Loss D: 0.515306, Loss G: 0.756501\n",
            "Epoch 20/50 Batch 400/600                   Loss D: 0.341594, Loss G: 1.810006\n",
            "Epoch 21/50 Batch 0/600                   Loss D: 0.372171, Loss G: 2.363628\n",
            "Epoch 21/50 Batch 400/600                   Loss D: 0.345228, Loss G: 1.372415\n",
            "Epoch 22/50 Batch 0/600                   Loss D: 0.340438, Loss G: 1.450029\n",
            "Epoch 22/50 Batch 400/600                   Loss D: 0.595917, Loss G: 0.617807\n",
            "Epoch 23/50 Batch 0/600                   Loss D: 0.712724, Loss G: 3.796911\n",
            "Epoch 23/50 Batch 400/600                   Loss D: 0.437655, Loss G: 0.980894\n",
            "Epoch 24/50 Batch 0/600                   Loss D: 0.404739, Loss G: 2.179902\n",
            "Epoch 24/50 Batch 400/600                   Loss D: 0.368479, Loss G: 1.661641\n",
            "Epoch 25/50 Batch 0/600                   Loss D: 0.391031, Loss G: 2.450782\n",
            "Epoch 25/50 Batch 400/600                   Loss D: 0.378645, Loss G: 2.271366\n",
            "Epoch 26/50 Batch 0/600                   Loss D: 0.410286, Loss G: 1.823630\n",
            "Epoch 26/50 Batch 400/600                   Loss D: 0.403706, Loss G: 1.236568\n",
            "Epoch 27/50 Batch 0/600                   Loss D: 0.390589, Loss G: 1.780166\n",
            "Epoch 27/50 Batch 400/600                   Loss D: 0.450017, Loss G: 0.960732\n",
            "Epoch 28/50 Batch 0/600                   Loss D: 0.387996, Loss G: 1.252961\n",
            "Epoch 28/50 Batch 400/600                   Loss D: 0.423280, Loss G: 1.518298\n",
            "Epoch 29/50 Batch 0/600                   Loss D: 0.383065, Loss G: 1.979631\n",
            "Epoch 29/50 Batch 400/600                   Loss D: 0.448683, Loss G: 1.655574\n",
            "Epoch 30/50 Batch 0/600                   Loss D: 0.487720, Loss G: 2.886582\n",
            "Epoch 30/50 Batch 400/600                   Loss D: 0.460771, Loss G: 1.682283\n",
            "Epoch 31/50 Batch 0/600                   Loss D: 0.419253, Loss G: 1.730742\n",
            "Epoch 31/50 Batch 400/600                   Loss D: 0.387975, Loss G: 1.560537\n",
            "Epoch 32/50 Batch 0/600                   Loss D: 0.395230, Loss G: 2.196034\n",
            "Epoch 32/50 Batch 400/600                   Loss D: 0.398673, Loss G: 1.195881\n",
            "Epoch 33/50 Batch 0/600                   Loss D: 0.415771, Loss G: 2.043348\n",
            "Epoch 33/50 Batch 400/600                   Loss D: 0.373067, Loss G: 1.447443\n",
            "Epoch 34/50 Batch 0/600                   Loss D: 0.454710, Loss G: 1.500309\n",
            "Epoch 34/50 Batch 400/600                   Loss D: 0.405344, Loss G: 1.168660\n",
            "Epoch 35/50 Batch 0/600                   Loss D: 0.399427, Loss G: 1.278797\n",
            "Epoch 35/50 Batch 400/600                   Loss D: 0.497091, Loss G: 2.182806\n",
            "Epoch 36/50 Batch 0/600                   Loss D: 0.462648, Loss G: 0.981566\n",
            "Epoch 36/50 Batch 400/600                   Loss D: 0.529773, Loss G: 2.165082\n",
            "Epoch 37/50 Batch 0/600                   Loss D: 0.361707, Loss G: 1.481724\n",
            "Epoch 37/50 Batch 400/600                   Loss D: 0.415182, Loss G: 1.858900\n",
            "Epoch 38/50 Batch 0/600                   Loss D: 0.412647, Loss G: 1.000003\n",
            "Epoch 38/50 Batch 400/600                   Loss D: 0.491775, Loss G: 0.795355\n",
            "Epoch 39/50 Batch 0/600                   Loss D: 0.439137, Loss G: 1.134172\n",
            "Epoch 39/50 Batch 400/600                   Loss D: 0.369562, Loss G: 1.651224\n",
            "Epoch 40/50 Batch 0/600                   Loss D: 0.604439, Loss G: 2.661099\n",
            "Epoch 40/50 Batch 400/600                   Loss D: 0.514634, Loss G: 2.491535\n",
            "Epoch 41/50 Batch 0/600                   Loss D: 0.414538, Loss G: 1.742406\n",
            "Epoch 41/50 Batch 400/600                   Loss D: 0.394486, Loss G: 1.217333\n",
            "Epoch 42/50 Batch 0/600                   Loss D: 0.369175, Loss G: 1.253890\n",
            "Epoch 42/50 Batch 400/600                   Loss D: 0.488357, Loss G: 0.985243\n",
            "Epoch 43/50 Batch 0/600                   Loss D: 0.408496, Loss G: 1.993705\n",
            "Epoch 43/50 Batch 400/600                   Loss D: 0.412885, Loss G: 1.368521\n",
            "Epoch 44/50 Batch 0/600                   Loss D: 0.454227, Loss G: 1.621152\n",
            "Epoch 44/50 Batch 400/600                   Loss D: 0.455990, Loss G: 1.284671\n",
            "Epoch 45/50 Batch 0/600                   Loss D: 0.451706, Loss G: 1.033588\n",
            "Epoch 45/50 Batch 400/600                   Loss D: 0.427086, Loss G: 1.280011\n",
            "Epoch 46/50 Batch 0/600                   Loss D: 0.393369, Loss G: 1.985806\n",
            "Epoch 46/50 Batch 400/600                   Loss D: 0.450163, Loss G: 0.901996\n",
            "Epoch 47/50 Batch 0/600                   Loss D: 0.349683, Loss G: 1.727293\n",
            "Epoch 47/50 Batch 400/600                   Loss D: 0.361175, Loss G: 1.447888\n",
            "Epoch 48/50 Batch 0/600                   Loss D: 0.447889, Loss G: 1.633722\n",
            "Epoch 48/50 Batch 400/600                   Loss D: 0.500365, Loss G: 0.860263\n",
            "Epoch 49/50 Batch 0/600                   Loss D: 0.406369, Loss G: 1.870188\n",
            "Epoch 49/50 Batch 400/600                   Loss D: 0.369036, Loss G: 1.331958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')"
      ],
      "metadata": {
        "id": "QV7ne0h-Rf3i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(64, latent_dim, device=device)\n",
        "    generated_imgs = generator(z)\n",
        "    vutils.save_image(generated_imgs.data, 'images/generated_samples.png', nrow=8, normalize=True)"
      ],
      "metadata": {
        "id": "O1i_9jtmQxIO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}